services:
  broker:
    image: apache/kafka:latest
    user: root
    hostname: broker
    container_name: broker
    ports:
      - 9092:9092
    volumes:
      - kafka_data:/tmp/kraft-combined-logs
    environment:
      # --- Tối ưu RAM cho Kafka (Quan trọng) ---
      KAFKA_HEAP_OPTS: "-Xmx400M -Xms400M"
      # -----------------------------------------
      KAFKA_BROKER_ID: "1"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: "1"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    deploy:
      resources:
        limits:
          memory: 600M

  producer: 
    build: 
      context: .
      dockerfile: kafka/Dockerfile
    depends_on:
      - broker
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=broker:29092
    command: sh -c "sleep 20 && uv run python producer.py" # Tăng sleep để Kafka kịp thở
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G

  cassandra:
    image: cassandra:4.1
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      - CASSANDRA_CLUSTER_NAME=TaxiCluster
      - CASSANDRA_DC=datacenter1
      - CASSANDRA_RACK=rack1
      # --- Tối ưu RAM cho Cassandra (Cực kỳ quan trọng) ---
      # Giới hạn Heap xuống 2GB (Mặc định nó có thể ăn tới 4GB)
      - MAX_HEAP_SIZE=2048M
      - HEAP_NEWSIZE=200M
      # ----------------------------------------------------
    volumes:
      - cassandra_data:/var/lib/cassandra
      - ./cassandra:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
      interval: 20s
      timeout: 10s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 2.5G

  spark:
    build:
      context: .
      dockerfile: spark/Dockerfile
    container_name: spark
    depends_on:
      cassandra:
        condition: service_healthy  
      broker:
        condition: service_started
      namenode: # Spark cần chờ HDFS
        condition: service_started
    ports:
      - "4040:4040"
    volumes:
      - ./spark:/opt/spark-apps
      - spark-checkpoints:/tmp/spark_checkpoints
    environment:
      - SPARK_LOCAL_DIRS=/tmp
      - KAFKA_BOOTSTRAP_SERVERS=broker:29092
      - CASSANDRA_HOST=cassandra
    command: >
      /opt/spark/bin/spark-submit
      --master local[*]
      --jars /opt/spark-jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,/opt/spark-jars/kafka-clients-3.4.1.jar,/opt/spark-jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,/opt/spark-jars/commons-pool2-2.11.1.jar,/opt/spark-jars/spark-cassandra-connector-assembly_2.12-3.5.1.jar
      --conf spark.sql.streaming.checkpointLocation=/tmp/spark_checkpoints
      /opt/spark-apps/streaming.py
    deploy:
      resources:
        limits:
          memory: 2G

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ADMIN_USER=admin
      - GF_INSTALL_PLUGINS=hadesarchitect-cassandra-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - cassandra
    deploy:
      resources:
        limits:
          memory: 400M

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=broker:29092
      - KAFKA_CLUSTERS_0_METRICS_PORT=9997
    depends_on:
      - broker
volumes:
  cassandra_data:
  grafana_data:
  spark-checkpoints:
  kafka_data:

    # The commented out section below is an example of how to define a PostgreSQL
    # database that your application can use. `depends_on` tells Docker Compose to
    # start the database before your application. The `db-data` volume persists the
    # database data between container restarts. The `db-password` secret is used
    # to set the database password. You must create `db/password.txt` and add
    # a password of your choosing to it before running `docker compose up`.
    #     depends_on:
    #       db:
    #         condition: service_healthy
    #   db:
    #     image: postgres
    #     restart: always
    #     user: postgres
    #     secrets:
    #       - db-password
    #     volumes:
    #       - db-data:/var/lib/postgresql/data
    #     environment:
    #       - POSTGRES_DB=example
    #       - POSTGRES_PASSWORD_FILE=/run/secrets/db-password
    #     expose:
    #       - 5432
    #     healthcheck:
    #       test: [ "CMD", "pg_isready" ]
    #       interval: 10s
    #       timeout: 5s
    #       retries: 5
    # volumes:
    #   db-data:
    # secrets:
    #   db-password:
    #     file: db/password.txt
